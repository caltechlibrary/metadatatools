
# metadatautils

This project was inspired by the [idutils](https://idutils.readthedocs.io/en/latest/) Python package. I needed something similar but in TypeScript.  I was dreading porting the Python code to TypeScript. I was dreading starting with a port of the Python code to TypeScript.  I also need to work with CiteProc records so that would be helpful in this package as well. I decided to follow a suggestion from my colleague [Tommy](https://github.com/t4k). 

Normally I find most "code suggestion" systems interruptive. Indeed I find the conversational style of the ChatGPT interface doesn't lend itself to flow for me. I think why this worked for me was that I wanted reference materials before I started coding and ChatGPT provided both the code and explanations. It spead up that part of the project.

The initial flow was in writing a simple TypeScript program to generate a list of questions I could send into ChatGPT. Retreiving the results was an mechanical experience for me.  Reviewing the transcript as a [Markdown document](chatgpt_dialog.md) I could take a high level view of how I wanted the Deno module to work and tease out the organization of the functionalitity.  I was pleased to find that the generated code was often nicely commented. I also liked that the question wasn't a single sentence but a short paragraph that included an attribution and copyright question so I would know what was likely to be safe to include directly and what I might wish to avoid.

## Deno and TypeScript approach
 
In terms of code maintenance Deno's ES module structure is more convienent in terms of code layout.  A `deps.ts` can define the dependency relationships. A `mod.ts` can define the browser module reference.  Each identifier type has it's own small TypeScript document and tests.

Since the questions to used a common structure I wrote a simple TypeScript program to generate a text file to use as the first draft of a question list for ChatGPT. I edit the result then started a session with ChatGPT. I then reviewed the resulting [dialog](chatgpt_dialog.md) and started organizing the project files as needed. This resulted in some rewriting and refactoring of the generated code and example materials.

## Current Conclusions

Because I could quickly assemble reference material through ChatGPT I was able to quickly code a base line. The caveat is you must actually read and understand the code generated by the LLM.  While I found it helpful for explainations I was asking about well documented specifications (e.g. ORCID, ROR, ISNI, ISSN, ISBN). In most of the cases I was familair enough to gage correctness be it "looking correct" based on my past experience but again you need to verify that. It is too easy to assume the machine is correct.  I will likely pull some of the test sets from the various specifications and add those manually to test the generated code. I am also likely to use a different LLM to do a code review (e.g. CoPilot Code Review available on GitHub).

ChatGPT probably saved me a day or two in research. Not much in my own thinking and given that I need to read, understand and improve the code I may not have saved asignificant time versus writing form scratch.   This value of the ChatGPT experience was as a partner in a dialect exercise in working on the project. It slowed me down to think more. It left like the advantage I had when I first used a word processor. It still took the same amount of time to write the paper but it was a more polished result for the same amount of time.  The time I needed to invest will still significant as was the case here.

## Identifier types

## Prompt questions for code generation

~~~
//
// This following generates a list of questions to feed into an LLM for code generation.
//
const identifier_types: object = {
    "ISBN": "ISBN",
    "ISSN": "ISSN",
    "DOI": "DOI",
    "ISNI": "ISNI",
    "ORCID": "ORCID",
    "ROR": "ROR",
    "ISTC": "ISTC (International Standard Text Code)",
    "handle": "handle identifier",
    "EAN": "EAN (International Article Number (EAN-13 or EAN-8))",
    "URL": "URL",
    "URI": "URI",
    "URN": "URL",
    "PURL": "PURL",
    "ADS": "ADS bibliographic code",
    "arXiv": "arXiv ID",
    "PMID": "PubMed ID",
    "PMCID": "PubMed Central ID",
    "GND": "GND Identifier",
    "SRA": "SRA accession identifier",
    "BioProject": "BioProject accession identifier",
    "BioSample": "BioSample accession identifier",
    "Ensembl": "Ensembl accession identifier",
    "UniProt": "UniProt accession identifier",
    "RefSeq": "RefSeq accession identifier",
    "Genome": "GenBank or RefSeq genome assembly accession identifier",
    "detect_identifier_schemes": "detect identifier schemes",
    "fundref": "FundRef IDs",
};
let i = 1;
for (let k of Object.keys(identifier_types)) {
    console.log(`> ${i}. How do I write a validator, verifier and normalize functions for ${identifier_types[k]} in Deno and TypeScript? What is the copyright or attribution requirements to use this code?`);
    console.log("");
    i++;
}
~~~

I modified the DOI question to include verification via CrossRef and DataCite as the first results only include verification via CrossRef and our DOI spread over both systems.

